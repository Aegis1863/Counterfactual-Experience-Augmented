{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "highway\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utils.highway_utils import train_PPO_agent, compute_advantage, read_ckp\n",
    "from utils.cvae import CVAE, cvae_train\n",
    "# from dynamic_model.train_Ensemble_dynamic_model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.h_1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h_1(F.relu(self.fc1(x))))\n",
    "        return F.softmax(self.fc2(x), dim=-1)\n",
    "    \n",
    "class ValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.h_1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h_1(F.relu(self.fc1(x))))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        hidden_dim: int,\n",
    "        action_dim: int,\n",
    "        cvae: object=None,\n",
    "        actor_lr: float=1e-4,\n",
    "        critic_lr: float=5e-3,\n",
    "        gamma: float=0.9,\n",
    "        lmbda: float=0.9,\n",
    "        epochs: int=20,\n",
    "        eps: float=0.2,\n",
    "        device: str='cpu',\n",
    "    ):\n",
    "        \n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.critic = ValueNet(state_dim, hidden_dim).to(device)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
    "        self.gamma = gamma  # 时序差分学习率\n",
    "        self.lmbda = lmbda\n",
    "        self.epochs = epochs  # 一条序列的数据用来训练轮数\n",
    "        self.eps = eps  # PPO中截断范围的参数\n",
    "        self.device = device\n",
    "        if cvae:\n",
    "            self.cvae = cvae.to(device)\n",
    "            self.cvae_optimizer = torch.optim.Adam(self.cvae.parameters(), lr=1e-3)\n",
    "        else:\n",
    "            self.cvae = None\n",
    "\n",
    "    def take_action(self, state) -> list:\n",
    "        state = torch.tensor(state[np.newaxis, :], dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(np.array(transition_dict['states']), dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(np.array(transition_dict['actions']), dtype=torch.int64).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(np.array(transition_dict['rewards']), dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(np.array(transition_dict['next_states']), dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(np.array(transition_dict['dones']), dtype=torch.int).view(-1, 1).to(self.device)\n",
    "        truncated = torch.tensor(np.array(transition_dict['truncated']), dtype=torch.int).view(-1, 1).to(self.device)\n",
    "        \n",
    "        # * 技巧\n",
    "        # self.train_cvae(states, next_states)  # 训练 vae, 如果是已经预训练好的就无需训练\n",
    "        # self.cvae_generate(32)  # 生成 cvae 图像观察效果\n",
    "        if self.cvae:\n",
    "            pre_next_state = self.predict_next_state(states, next_states)\n",
    "            target_q1 = self.critic(pre_next_state).detach()\n",
    "            target_q2 = self.critic(next_states).detach()\n",
    "            target_q = torch.min(target_q1, target_q2)\n",
    "        else:\n",
    "            target_q = self.critic(next_states).detach()\n",
    "            \n",
    "        td_target = rewards + self.gamma * target_q * (1 - dones | truncated)\n",
    "        td_delta = td_target - self.critic(states)\n",
    "        advantage = compute_advantage(self.gamma, self.lmbda, td_delta.cpu()).to(self.device)\n",
    "        # 所谓的另一个演员就是原来的演员的初始状态\n",
    "        old_log_probs = torch.log(self.actor(states).gather(1, actions)).detach()\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            log_probs = torch.log(self.actor(states).gather(1, actions))\n",
    "            ratio = torch.exp(log_probs - old_log_probs)  # 重要性采样系数\n",
    "            surr1 = ratio * advantage  # 重要性采样\n",
    "            surr2 = torch.clip(ratio, 1 - self.eps, 1 + self.eps) * advantage\n",
    "            actor_loss = torch.mean(-torch.min(surr1, surr2))\n",
    "            critic_loss = torch.mean(F.mse_loss(self.critic(states), td_target.detach()))\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            critic_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "            self.critic_optimizer.step()\n",
    "            \n",
    "    def train_cvae(self, state, next_state):\n",
    "        vae_action = next_state[:, :4]\n",
    "        diff_state = next_state[:, 5:] - state[:, 5:]\n",
    "        train_loss = cvae_train(self.cvae, diff_state, vae_action, self.cvae_optimizer)\n",
    "        return train_loss\n",
    "    \n",
    "    def predict_next_state(self, state, next_state):\n",
    "        action = state[:, :4]\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(state.shape[0], 32).to(device)  # 随机采样的\n",
    "            generated = self.cvae.decode(sample, action)\n",
    "        pre_next_state = torch.concat([next_state[:, :5], state[:, 5:] + generated], dim=-1)\n",
    "        return pre_next_state\n",
    "    \n",
    "    \n",
    "# * --------------------- 参数 -------------------------\n",
    "# 环境相关\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "env = gym.make('highway-v0', render_mode='human')\n",
    "seed = 42\n",
    "# env = gym.make(\"highway-v0\", render_mode='rgb_array')\n",
    "\n",
    "\n",
    "# PPO相关\n",
    "actor_lr = 5e-4\n",
    "critic_lr = 1e-3\n",
    "lmbda = 0.95  # 似乎可以去掉，这一项仅用于调整计算优势advantage时，额外调整折算奖励的系数\n",
    "gamma = 0.98  # 时序差分学习率，也作为折算奖励的系数之一\n",
    "total_epochs = 1  # 迭代轮数\n",
    "eps = 0.2  # 截断范围参数, 1-eps ~ 1+eps\n",
    "epochs = 10  # PPO中一条序列训练多少轮，和迭代算法无关\n",
    "\n",
    "# 神经网络相关\n",
    "hidden_dim = 64\n",
    "state_dim = torch.multiply(*env.observation_space.shape)\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# VAE\n",
    "# cvae = CVAE(32, action_dim, 32)  # 在线训练\n",
    "# 需要预训练\n",
    "# cvae = torch.load(f'model/cvae/{args.cvae_kind}.pt', map_location=device) if args.cvae_kind else None  \n",
    "\n",
    "# 任务相关\n",
    "system_type = sys.platform  # 操作系统\n",
    "print('device:', device)\n",
    "\n",
    "# * ----------------------- 训练 ----------------------------\n",
    "CKP_PATH = f'ckpt/highway/PPO/{seed}/{system_type}.pt'\n",
    "# env = gym.make(\"highway-v0\", render_mode='rgb_array')\n",
    "agent = PPO(state_dim, hidden_dim, action_dim, None, actor_lr, \n",
    "            critic_lr, gamma, lmbda, epochs, eps, device)\n",
    "s_epoch, s_episode, return_list, time_list, seed_list = read_ckp(CKP_PATH, agent, 'PPO')\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = truncated = False\n",
    "total_reward = 0\n",
    "while not (done | truncated):\n",
    "    obs = obs.reshape(-1)\n",
    "    action = agent.take_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "print(round(total_reward, 3))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[ checkpoint ]\u001b[0m 读取已有模型权重和训练数据...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils.highway_utils import read_ckp, train_DQN\n",
    "from utils.cvae import CVAE, cvae_train\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class VAnet(torch.nn.Module):\n",
    "    ''' 只有一层隐藏层的A网络和V网络 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(VAnet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)  # 共享网络部分\n",
    "        self.h_1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_A = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.fc_V = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        A = self.fc_A(F.relu(self.h_1(F.relu(self.fc1(x)))))\n",
    "        V = self.fc_V(F.relu(self.h_1(F.relu(self.fc1(x)))))\n",
    "        Q = V + A - A.mean(-1).view(-1, 1)  # Q值由V值和A值计算得到\n",
    "        return Q\n",
    "    \n",
    "class DQN:\n",
    "    ''' DQN算法,包括Double DQN '''\n",
    "    \n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, learning_rate,\n",
    "                 gamma, epsilon, update_interval, sta, device,):\n",
    "        \n",
    "        self.action_dim = action_dim\n",
    "        self.q_net = VAnet(state_dim, hidden_dim, self.action_dim).to(device)\n",
    "        self.target_q_net = VAnet(state_dim, hidden_dim, self.action_dim).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr=learning_rate)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.update_interval = update_interval\n",
    "        self.sta = sta\n",
    "        # self.sta = sta_kind\n",
    "        self.count = 0\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(self.action_dim)\n",
    "        else:\n",
    "            state = torch.tensor(state, dtype=torch.float).to(self.device)\n",
    "            action = self.q_net(state).argmax().item()\n",
    "        return action\n",
    "\n",
    "    def max_q_value(self, state):\n",
    "        state = torch.tensor(state, dtype=torch.float).to(self.device)\n",
    "        return self.q_net(state).max().item()\n",
    "    \n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'], dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions'], dtype=torch.int64).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'], dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'], dtype=torch.int).view(-1, 1).to(self.device)\n",
    "        truncated = torch.tensor(transition_dict['truncated'], dtype=torch.int).view(-1, 1).to(self.device)\n",
    "\n",
    "        q_values = self.q_net(states).gather(1, actions)  # Q值\n",
    "        max_action = self.q_net(next_states).max(1)[1].view(-1, 1)\n",
    "        \n",
    "        # * 技巧一\n",
    "        if self.sta and self.sta.quality > 0.3:\n",
    "            pre_next_state = self.predict_next_state(states, next_states)\n",
    "            target_q1 = self.target_q_net(pre_next_state).detach()\n",
    "            target_q2 = self.target_q_net(next_states).detach()\n",
    "            max_next_q_values = torch.min(target_q1, target_q2)\n",
    "        else:\n",
    "            max_next_q_values = self.target_q_net(next_states).gather(1, max_action)\n",
    "            \n",
    "        q_targets = rewards + self.gamma * max_next_q_values * (1 - dones | truncated)  # TD误差目标\n",
    "        dqn_loss = torch.mean(F.mse_loss(q_values, q_targets))  # 均方误差损失函数\n",
    "        self.optimizer.zero_grad()  # PyTorch中默认梯度会累积,这里需要显式将梯度置为0\n",
    "        dqn_loss.backward()  # 反向传播更新参数\n",
    "        self.optimizer.step() # 执行Adam梯度下降\n",
    "\n",
    "        if self.count % self.update_interval == 0:\n",
    "            self.target_q_net.load_state_dict(self.q_net.state_dict())  # 更新目标网络\n",
    "        self.count += 1\n",
    "    \n",
    "    def train_cvae(self, state, next_state, test_and_feedback, batch_size):\n",
    "        vae_action = next_state[:, :4]\n",
    "        diff_state = next_state[:, 5:] - state[:, 5:]\n",
    "        loss = cvae_train(self.sta, self.device, diff_state, vae_action, self.sta_optimizer, test_and_feedback, batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def predict_next_state(self, state, next_state):\n",
    "        action = state[:, :4]\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(state.shape[0], 32).to(device)  # 随机采样的\n",
    "            generated = self.sta.decode(sample, action)\n",
    "        pre_next_state = torch.concat([next_state[:, :5], state[:, 5:] + generated], dim=-1)\n",
    "        return pre_next_state\n",
    "\n",
    "    \n",
    "# * --------------------- 参数 -------------------------\n",
    "# 环境相关\n",
    "env = gym.make(\"highway-v0\", render_mode='rgb_array')\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "mission = 'highway'\n",
    "model_name = 'DQN~cvae'\n",
    "system_type = 'linux'  # sys.platform  # 操作系统\n",
    "seed = 43\n",
    "\n",
    "# DQN相关\n",
    "total_epoch = 1  # 迭代数, 无需多次迭代\n",
    "gamma = 0.98\n",
    "epsilon = 1  # 刚开始随机动作,更新中线性降低\n",
    "update_interval = 50  # 若干回合更新一次目标网络\n",
    "minimal_size = 500  # 最小经验数\n",
    "batch_size = 128\n",
    "buffer_size = 20000\n",
    "\n",
    "# 神经网络相关\n",
    "lr = 2e-3\n",
    "state_dim = torch.multiply(*env.observation_space.shape)\n",
    "hidden_dim = 256\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# * ----------------------- 训练 ----------------------------\n",
    "CKP_PATH = f'ckpt/highway/{model_name}/{seed}/{system_type}.pt'\n",
    "agent = DQN(state_dim, hidden_dim, action_dim, lr, gamma, epsilon, update_interval, None, device)\n",
    "s_epoch, s_episode, return_list, time_list, seed_list, replay_buffer = read_ckp(CKP_PATH, agent, model_name, 20000)\n",
    "agent.epsilon = 0\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.735\n"
     ]
    }
   ],
   "source": [
    "ACTIONS_ALL = {\n",
    "        0: '左转',\n",
    "        1: '匀速',\n",
    "        2: '右转',\n",
    "        3: '加速',\n",
    "        4: '减速'\n",
    "    }\n",
    "\n",
    "env = gym.make(\"highway-v0\", render_mode='human')\n",
    "env.configure({\n",
    "    \"lanes_count\": 4,\n",
    "    \"vehicles_density\": 1.5,\n",
    "    \"duration\": 100,\n",
    "    # \"collision_reward\": -30,\n",
    "    # \"right_lane_reward\": 0.2,\n",
    "    # \"high_speed_reward\": 0,\n",
    "    # \"offroad_terminal\": False,\n",
    "    # \"reward_speed_range\": [20, 30],\n",
    "    # \"manual_control\": True\n",
    "})\n",
    "\n",
    "'''\n",
    "env.configure({\n",
    "    \"lanes_count\": 3,\n",
    "    \"vehicles_density\": 1.5,\n",
    "    \"duration\": 100,\n",
    "    \"collision_reward\": -30,\n",
    "    \"right_lane_reward\": 0.2,\n",
    "    \"high_speed_reward\": 2,\n",
    "    \"offroad_terminal\": False,\n",
    "    # \"reward_speed_range\": [20, 30],\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",\n",
    "        \"longitudinal\": True,\n",
    "        \"lateral\": True,\n",
    "        \"target_speeds\": [17, 23, 30],  # TODO 调整速度\n",
    "    },\n",
    "    # \"manual_control\": True\n",
    "})'''\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = truncated = False\n",
    "total_reward = 0\n",
    "while not (done | truncated):\n",
    "    obs = obs.reshape(-1)\n",
    "    action = agent.take_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    print(ACTIONS_ALL[action], end='\\r')\n",
    "    \n",
    "print(round(total_reward, 3))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from utils.RDQN_modules import *\n",
    "import torch\n",
    "env = gym.make(\"highway-v0\", render_mode='human')\n",
    "agent = DQNAgent(env, 0, 128, 0, 42, n_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('ckpt/highway/RDQN_Normal/42/linux.pt')\n",
    "agent.dqn.load_state_dict(checkpoint[\"best_weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.294\n"
     ]
    }
   ],
   "source": [
    "env.configure({\n",
    "    \"lanes_count\": 4,\n",
    "    \"vehicles_density\": 1.5,\n",
    "    \"duration\": 100,\n",
    "    # \"collision_reward\": -30,\n",
    "    # \"right_lane_reward\": 0.2,\n",
    "    # \"high_speed_reward\": 0,\n",
    "    # \"offroad_terminal\": False,\n",
    "    # \"reward_speed_range\": [20, 30],\n",
    "    # \"manual_control\": True\n",
    "})\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = truncated = False\n",
    "total_reward = 0\n",
    "while not (done | truncated):\n",
    "    obs = obs.reshape(-1)\n",
    "    action = agent.select_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "print(round(total_reward, 3))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.RDQN_modules import *\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = torch.load('ckpt/CartPole-v1/RDQN_Normal/42/win32.pt')['replay_buffer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = buffer.obs_buf\n",
    "next_state = buffer.next_obs_buf\n",
    "action = torch.tensor(buffer.acts_buf).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_state = next_state - state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.6853214e-03,  1.9481656e-01,  6.7697391e-03, -2.8597903e-01],\n",
       "       [-3.7889909e-03,  1.9471259e-01,  1.0501593e-03, -2.8378519e-01],\n",
       "       [ 1.0526180e-04, -1.9552201e-01, -4.6255458e-03,  3.0164051e-01],\n",
       "       ...,\n",
       "       [-2.2002496e-05, -1.9592384e-01, -1.8202960e-03,  3.1088713e-01],\n",
       "       [-3.9404794e-03,  1.9424982e-01,  4.3974482e-03, -2.7389818e-01],\n",
       "       [-5.5482145e-05, -1.9595633e-01, -1.0805167e-03,  3.1164593e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_dim = diff_state.shape[-1]\n",
    "condition_dim = 1\n",
    "latent_dim = input_dim\n",
    "batch_size = 16\n",
    "\n",
    "fig_path = f'image/VAE/regular/{batch_size}/'\n",
    "\n",
    "# 训练\n",
    "model = CVAE(input_dim, condition_dim, latent_dim).to(device)\n",
    "num_epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "quality = []\n",
    "for epoch in trange(num_epochs, ncols=70):\n",
    "    cvae_train(model, device, diff_state, action, optimizer, False, batch_size)\n",
    "    quality.append(model.generate_test(32, 4, epoch, fig_path))\n",
    "print(f'\\n==> Generate silhouette score: {[round(i, 3) for i in quality]}')\n",
    "plt.figure()\n",
    "sns.lineplot(quality)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.grid()\n",
    "plt.savefig(f'{fig_path}/Silhouette score.png')\n",
    "plt.close()\n",
    "torch.save(model, f'model/cvae/CartPole-v1/regular.pt')\n",
    "print(model.quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 经验分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.RDQN_modules import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = torch.load('ckpt/sumo/CEA/42_linux.pt')['replay_buffer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = buffer.exp_type_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_priorities(buffer):\n",
    "    \"\"\"Check and print the priority of each experience.\"\"\"\n",
    "    priority = []\n",
    "    for idx in range(len(buffer)):\n",
    "        # 获取存储的优先级的alpha次方\n",
    "        stored_priority_alpha = buffer.sum_tree[idx]\n",
    "        # 还原原始优先级值，如果你知道alpha的值的话\n",
    "        original_priority = stored_priority_alpha**(1/buffer.alpha)\n",
    "        # print(f\"Experience at index {idx} has a priority of {original_priority}\")\n",
    "        priority.append(original_priority)\n",
    "    return priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri = check_priorities(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'type': exp_type, 'priority': pri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.287539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.155241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.855604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.325098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.573883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.308534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.356762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.145331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.527318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.029723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  priority\n",
       "0       1.0  3.287539\n",
       "1       1.0  3.155241\n",
       "2       1.0  2.855604\n",
       "3       1.0  3.325098\n",
       "4       1.0  3.573883\n",
       "...     ...       ...\n",
       "19995   1.0  3.308534\n",
       "19996   1.0  3.356762\n",
       "19997   1.0  3.145331\n",
       "19998   1.0  3.527318\n",
       "19999   1.0  7.029723\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.kdeplot(data[data['type']==1]['priority'], color='r', label=f'Real exp: {sum(exp_type==0)}')\n",
    "sns.kdeplot(data[data['type']==0]['priority'], color='blue', label=f'Virtual exp: {sum(exp_type==1)}')\n",
    "plt.xlabel('Priority')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig('C:/Users/Bowen/Desktop/repos/My_Papers/VAE based model/figures/sumo-sta-exp.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pool size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
