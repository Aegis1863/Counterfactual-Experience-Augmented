{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "highway\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utils.highway_utils import train_PPO_agent, compute_advantage, read_ckp\n",
    "from utils.cvae import CVAE, cvae_train\n",
    "# from dynamic_model.train_Ensemble_dynamic_model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.h_1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h_1(F.relu(self.fc1(x))))\n",
    "        return F.softmax(self.fc2(x), dim=-1)\n",
    "    \n",
    "class ValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.h_1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h_1(F.relu(self.fc1(x))))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        hidden_dim: int,\n",
    "        action_dim: int,\n",
    "        cvae: object=None,\n",
    "        actor_lr: float=1e-4,\n",
    "        critic_lr: float=5e-3,\n",
    "        gamma: float=0.9,\n",
    "        lmbda: float=0.9,\n",
    "        epochs: int=20,\n",
    "        eps: float=0.2,\n",
    "        device: str='cpu',\n",
    "    ):\n",
    "        \n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.critic = ValueNet(state_dim, hidden_dim).to(device)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
    "        self.gamma = gamma  # 时序差分学习率\n",
    "        self.lmbda = lmbda\n",
    "        self.epochs = epochs  # 一条序列的数据用来训练轮数\n",
    "        self.eps = eps  # PPO中截断范围的参数\n",
    "        self.device = device\n",
    "        if cvae:\n",
    "            self.cvae = cvae.to(device)\n",
    "            self.cvae_optimizer = torch.optim.Adam(self.cvae.parameters(), lr=1e-3)\n",
    "        else:\n",
    "            self.cvae = None\n",
    "\n",
    "    def take_action(self, state) -> list:\n",
    "        state = torch.tensor(state[np.newaxis, :], dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(np.array(transition_dict['states']), dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(np.array(transition_dict['actions']), dtype=torch.int64).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(np.array(transition_dict['rewards']), dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(np.array(transition_dict['next_states']), dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(np.array(transition_dict['dones']), dtype=torch.int).view(-1, 1).to(self.device)\n",
    "        truncated = torch.tensor(np.array(transition_dict['truncated']), dtype=torch.int).view(-1, 1).to(self.device)\n",
    "        \n",
    "        # * 技巧\n",
    "        # self.train_cvae(states, next_states)  # 训练 vae, 如果是已经预训练好的就无需训练\n",
    "        # self.cvae_generate(32)  # 生成 cvae 图像观察效果\n",
    "        if self.cvae:\n",
    "            pre_next_state = self.predict_next_state(states, next_states)\n",
    "            target_q1 = self.critic(pre_next_state).detach()\n",
    "            target_q2 = self.critic(next_states).detach()\n",
    "            target_q = torch.min(target_q1, target_q2)\n",
    "        else:\n",
    "            target_q = self.critic(next_states).detach()\n",
    "            \n",
    "        td_target = rewards + self.gamma * target_q * (1 - dones | truncated)\n",
    "        td_delta = td_target - self.critic(states)\n",
    "        advantage = compute_advantage(self.gamma, self.lmbda, td_delta.cpu()).to(self.device)\n",
    "        # 所谓的另一个演员就是原来的演员的初始状态\n",
    "        old_log_probs = torch.log(self.actor(states).gather(1, actions)).detach()\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            log_probs = torch.log(self.actor(states).gather(1, actions))\n",
    "            ratio = torch.exp(log_probs - old_log_probs)  # 重要性采样系数\n",
    "            surr1 = ratio * advantage  # 重要性采样\n",
    "            surr2 = torch.clip(ratio, 1 - self.eps, 1 + self.eps) * advantage\n",
    "            actor_loss = torch.mean(-torch.min(surr1, surr2))\n",
    "            critic_loss = torch.mean(F.mse_loss(self.critic(states), td_target.detach()))\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            critic_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "            self.critic_optimizer.step()\n",
    "            \n",
    "    def train_cvae(self, state, next_state):\n",
    "        vae_action = next_state[:, :4]\n",
    "        diff_state = next_state[:, 5:] - state[:, 5:]\n",
    "        train_loss = cvae_train(self.cvae, diff_state, vae_action, self.cvae_optimizer)\n",
    "        return train_loss\n",
    "    \n",
    "    def predict_next_state(self, state, next_state):\n",
    "        action = state[:, :4]\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(state.shape[0], 32).to(device)  # 随机采样的\n",
    "            generated = self.cvae.decode(sample, action)\n",
    "        pre_next_state = torch.concat([next_state[:, :5], state[:, 5:] + generated], dim=-1)\n",
    "        return pre_next_state\n",
    "    \n",
    "    \n",
    "# * --------------------- 参数 -------------------------\n",
    "# 环境相关\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "env = gym.make('highway-v0', render_mode='human')\n",
    "seed = 42\n",
    "# env = gym.make(\"highway-v0\", render_mode='rgb_array')\n",
    "\n",
    "\n",
    "# PPO相关\n",
    "actor_lr = 5e-4\n",
    "critic_lr = 1e-3\n",
    "lmbda = 0.95  # 似乎可以去掉，这一项仅用于调整计算优势advantage时，额外调整折算奖励的系数\n",
    "gamma = 0.98  # 时序差分学习率，也作为折算奖励的系数之一\n",
    "total_epochs = 1  # 迭代轮数\n",
    "eps = 0.2  # 截断范围参数, 1-eps ~ 1+eps\n",
    "epochs = 10  # PPO中一条序列训练多少轮，和迭代算法无关\n",
    "\n",
    "# 神经网络相关\n",
    "hidden_dim = 64\n",
    "state_dim = torch.multiply(*env.observation_space.shape)\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# VAE\n",
    "# cvae = CVAE(32, action_dim, 32)  # 在线训练\n",
    "# 需要预训练\n",
    "# cvae = torch.load(f'model/cvae/{args.cvae_kind}.pt', map_location=device) if args.cvae_kind else None  \n",
    "\n",
    "# 任务相关\n",
    "system_type = sys.platform  # 操作系统\n",
    "print('device:', device)\n",
    "\n",
    "# * ----------------------- 训练 ----------------------------\n",
    "CKP_PATH = f'ckpt/highway/PPO/{seed}/{system_type}.pt'\n",
    "# env = gym.make(\"highway-v0\", render_mode='rgb_array')\n",
    "agent = PPO(state_dim, hidden_dim, action_dim, None, actor_lr, \n",
    "            critic_lr, gamma, lmbda, epochs, eps, device)\n",
    "s_epoch, s_episode, return_list, time_list, seed_list = read_ckp(CKP_PATH, agent, 'PPO')\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = truncated = False\n",
    "total_reward = 0\n",
    "while not (done | truncated):\n",
    "    obs = obs.reshape(-1)\n",
    "    action = agent.take_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "print(round(total_reward, 3))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[ checkpoint ]\u001b[0m 读取已有模型权重和训练数据...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils.highway_utils import read_ckp, train_DQN\n",
    "from utils.cvae import CVAE, cvae_train\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class VAnet(torch.nn.Module):\n",
    "    ''' 只有一层隐藏层的A网络和V网络 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(VAnet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)  # 共享网络部分\n",
    "        self.h_1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_A = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.fc_V = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        A = self.fc_A(F.relu(self.h_1(F.relu(self.fc1(x)))))\n",
    "        V = self.fc_V(F.relu(self.h_1(F.relu(self.fc1(x)))))\n",
    "        Q = V + A - A.mean(-1).view(-1, 1)  # Q值由V值和A值计算得到\n",
    "        return Q\n",
    "    \n",
    "class DQN:\n",
    "    ''' DQN算法,包括Double DQN '''\n",
    "    \n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, learning_rate,\n",
    "                 gamma, epsilon, update_interval, sta, device,):\n",
    "        \n",
    "        self.action_dim = action_dim\n",
    "        self.q_net = VAnet(state_dim, hidden_dim, self.action_dim).to(device)\n",
    "        self.target_q_net = VAnet(state_dim, hidden_dim, self.action_dim).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr=learning_rate)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.update_interval = update_interval\n",
    "        self.sta = sta\n",
    "        # self.sta = sta_kind\n",
    "        self.count = 0\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(self.action_dim)\n",
    "        else:\n",
    "            state = torch.tensor(state, dtype=torch.float).to(self.device)\n",
    "            action = self.q_net(state).argmax().item()\n",
    "        return action\n",
    "\n",
    "    def max_q_value(self, state):\n",
    "        state = torch.tensor(state, dtype=torch.float).to(self.device)\n",
    "        return self.q_net(state).max().item()\n",
    "    \n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'], dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions'], dtype=torch.int64).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'], dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'], dtype=torch.int).view(-1, 1).to(self.device)\n",
    "        truncated = torch.tensor(transition_dict['truncated'], dtype=torch.int).view(-1, 1).to(self.device)\n",
    "\n",
    "        q_values = self.q_net(states).gather(1, actions)  # Q值\n",
    "        max_action = self.q_net(next_states).max(1)[1].view(-1, 1)\n",
    "        \n",
    "        # * 技巧一\n",
    "        if self.sta and self.sta.quality > 0.3:\n",
    "            pre_next_state = self.predict_next_state(states, next_states)\n",
    "            target_q1 = self.target_q_net(pre_next_state).detach()\n",
    "            target_q2 = self.target_q_net(next_states).detach()\n",
    "            max_next_q_values = torch.min(target_q1, target_q2)\n",
    "        else:\n",
    "            max_next_q_values = self.target_q_net(next_states).gather(1, max_action)\n",
    "            \n",
    "        q_targets = rewards + self.gamma * max_next_q_values * (1 - dones | truncated)  # TD误差目标\n",
    "        dqn_loss = torch.mean(F.mse_loss(q_values, q_targets))  # 均方误差损失函数\n",
    "        self.optimizer.zero_grad()  # PyTorch中默认梯度会累积,这里需要显式将梯度置为0\n",
    "        dqn_loss.backward()  # 反向传播更新参数\n",
    "        self.optimizer.step() # 执行Adam梯度下降\n",
    "\n",
    "        if self.count % self.update_interval == 0:\n",
    "            self.target_q_net.load_state_dict(self.q_net.state_dict())  # 更新目标网络\n",
    "        self.count += 1\n",
    "    \n",
    "    def train_cvae(self, state, next_state, test_and_feedback, batch_size):\n",
    "        vae_action = next_state[:, :4]\n",
    "        diff_state = next_state[:, 5:] - state[:, 5:]\n",
    "        loss = cvae_train(self.sta, self.device, diff_state, vae_action, self.sta_optimizer, test_and_feedback, batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def predict_next_state(self, state, next_state):\n",
    "        action = state[:, :4]\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(state.shape[0], 32).to(device)  # 随机采样的\n",
    "            generated = self.sta.decode(sample, action)\n",
    "        pre_next_state = torch.concat([next_state[:, :5], state[:, 5:] + generated], dim=-1)\n",
    "        return pre_next_state\n",
    "\n",
    "    \n",
    "# * --------------------- 参数 -------------------------\n",
    "# 环境相关\n",
    "env = gym.make(\"highway-v0\", render_mode='rgb_array')\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "mission = 'highway'\n",
    "model_name = 'DQN~cvae'\n",
    "system_type = 'linux'  # sys.platform  # 操作系统\n",
    "seed = 43\n",
    "\n",
    "# DQN相关\n",
    "total_epoch = 1  # 迭代数, 无需多次迭代\n",
    "gamma = 0.98\n",
    "epsilon = 1  # 刚开始随机动作,更新中线性降低\n",
    "update_interval = 50  # 若干回合更新一次目标网络\n",
    "minimal_size = 500  # 最小经验数\n",
    "batch_size = 128\n",
    "buffer_size = 20000\n",
    "\n",
    "# 神经网络相关\n",
    "lr = 2e-3\n",
    "state_dim = torch.multiply(*env.observation_space.shape)\n",
    "hidden_dim = 256\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# * ----------------------- 训练 ----------------------------\n",
    "CKP_PATH = f'ckpt/highway/{model_name}/{seed}/{system_type}.pt'\n",
    "agent = DQN(state_dim, hidden_dim, action_dim, lr, gamma, epsilon, update_interval, None, device)\n",
    "s_epoch, s_episode, return_list, time_list, seed_list, replay_buffer = read_ckp(CKP_PATH, agent, model_name, 20000)\n",
    "agent.epsilon = 0\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.735\n"
     ]
    }
   ],
   "source": [
    "ACTIONS_ALL = {\n",
    "        0: '左转',\n",
    "        1: '匀速',\n",
    "        2: '右转',\n",
    "        3: '加速',\n",
    "        4: '减速'\n",
    "    }\n",
    "\n",
    "env = gym.make(\"highway-v0\", render_mode='human')\n",
    "env.configure({\n",
    "    \"lanes_count\": 4,\n",
    "    \"vehicles_density\": 1.5,\n",
    "    \"duration\": 100,\n",
    "    # \"collision_reward\": -30,\n",
    "    # \"right_lane_reward\": 0.2,\n",
    "    # \"high_speed_reward\": 0,\n",
    "    # \"offroad_terminal\": False,\n",
    "    # \"reward_speed_range\": [20, 30],\n",
    "    # \"manual_control\": True\n",
    "})\n",
    "\n",
    "'''\n",
    "env.configure({\n",
    "    \"lanes_count\": 3,\n",
    "    \"vehicles_density\": 1.5,\n",
    "    \"duration\": 100,\n",
    "    \"collision_reward\": -30,\n",
    "    \"right_lane_reward\": 0.2,\n",
    "    \"high_speed_reward\": 2,\n",
    "    \"offroad_terminal\": False,\n",
    "    # \"reward_speed_range\": [20, 30],\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",\n",
    "        \"longitudinal\": True,\n",
    "        \"lateral\": True,\n",
    "        \"target_speeds\": [17, 23, 30],  # TODO 调整速度\n",
    "    },\n",
    "    # \"manual_control\": True\n",
    "})'''\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = truncated = False\n",
    "total_reward = 0\n",
    "while not (done | truncated):\n",
    "    obs = obs.reshape(-1)\n",
    "    action = agent.take_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    print(ACTIONS_ALL[action], end='\\r')\n",
    "    \n",
    "print(round(total_reward, 3))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from utils.RDQN_modules import *\n",
    "import torch\n",
    "env = gym.make(\"highway-v0\", render_mode='human')\n",
    "agent = DQNAgent(env, 0, 128, 0, 42, n_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('ckpt/highway/RDQN_Normal/42/linux.pt')\n",
    "agent.dqn.load_state_dict(checkpoint[\"best_weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.294\n"
     ]
    }
   ],
   "source": [
    "env.configure({\n",
    "    \"lanes_count\": 4,\n",
    "    \"vehicles_density\": 1.5,\n",
    "    \"duration\": 100,\n",
    "    # \"collision_reward\": -30,\n",
    "    # \"right_lane_reward\": 0.2,\n",
    "    # \"high_speed_reward\": 0,\n",
    "    # \"offroad_terminal\": False,\n",
    "    # \"reward_speed_range\": [20, 30],\n",
    "    # \"manual_control\": True\n",
    "})\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = truncated = False\n",
    "total_reward = 0\n",
    "while not (done | truncated):\n",
    "    obs = obs.reshape(-1)\n",
    "    action = agent.select_action(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "print(round(total_reward, 3))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.RDQN_modules import *\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = torch.load('ckpt/CartPole-v1/RDQN_Normal/42/win32.pt')['replay_buffer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = buffer.obs_buf\n",
    "next_state = buffer.next_obs_buf\n",
    "action = torch.tensor(buffer.acts_buf).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_state = next_state - state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.6853214e-03,  1.9481656e-01,  6.7697391e-03, -2.8597903e-01],\n",
       "       [-3.7889909e-03,  1.9471259e-01,  1.0501593e-03, -2.8378519e-01],\n",
       "       [ 1.0526180e-04, -1.9552201e-01, -4.6255458e-03,  3.0164051e-01],\n",
       "       ...,\n",
       "       [-2.2002496e-05, -1.9592384e-01, -1.8202960e-03,  3.1088713e-01],\n",
       "       [-3.9404794e-03,  1.9424982e-01,  4.3974482e-03, -2.7389818e-01],\n",
       "       [-5.5482145e-05, -1.9595633e-01, -1.0805167e-03,  3.1164593e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_dim = diff_state.shape[-1]\n",
    "condition_dim = 1\n",
    "latent_dim = input_dim\n",
    "batch_size = 16\n",
    "\n",
    "fig_path = f'image/VAE/regular/{batch_size}/'\n",
    "\n",
    "# 训练\n",
    "model = CVAE(input_dim, condition_dim, latent_dim).to(device)\n",
    "num_epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "quality = []\n",
    "for epoch in trange(num_epochs, ncols=70):\n",
    "    cvae_train(model, device, diff_state, action, optimizer, False, batch_size)\n",
    "    quality.append(model.generate_test(32, 4, epoch, fig_path))\n",
    "print(f'\\n==> Generate silhouette score: {[round(i, 3) for i in quality]}')\n",
    "plt.figure()\n",
    "sns.lineplot(quality)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.grid()\n",
    "plt.savefig(f'{fig_path}/Silhouette score.png')\n",
    "plt.close()\n",
    "torch.save(model, f'model/cvae/CartPole-v1/regular.pt')\n",
    "print(model.quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 经验分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.RDQN_modules import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = torch.load('ckpt/sumo/CEA/43_linux.pt')['replay_buffer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = buffer.exp_type_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_priorities(buffer):\n",
    "    \"\"\"Check and print the priority of each experience.\"\"\"\n",
    "    priority = []\n",
    "    for idx in range(len(buffer)):\n",
    "        # 获取存储的优先级的alpha次方\n",
    "        stored_priority_alpha = buffer.sum_tree[idx]\n",
    "        # 还原原始优先级值，如果你知道alpha的值的话\n",
    "        original_priority = stored_priority_alpha**(1/buffer.alpha)\n",
    "        # print(f\"Experience at index {idx} has a priority of {original_priority}\")\n",
    "        priority.append(original_priority)\n",
    "    return priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri = check_priorities(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'type': exp_type, 'priority': pri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.272593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.516105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.878277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.486530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.139011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.762425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.421920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.499329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.179376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.943010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  priority\n",
       "0       1.0  3.272593\n",
       "1       1.0  3.516105\n",
       "2       1.0  2.878277\n",
       "3       1.0  3.486530\n",
       "4       1.0  3.139011\n",
       "...     ...       ...\n",
       "19995   1.0  2.762425\n",
       "19996   1.0  3.421920\n",
       "19997   1.0  3.499329\n",
       "19998   1.0  3.179376\n",
       "19999   1.0  6.943010\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "sns.kdeplot(data[data['type']==1]['priority'], color='r', label=f'Real exp: {sum(exp_type==0)}', lw=2)\n",
    "sns.kdeplot(data[data['type']==0]['priority'], color='blue', linestyle='--', label=f'Virtual exp: {sum(exp_type==1)}')\n",
    "plt.xlabel('Priority')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(f'C:/Users/Bowen/Desktop/repos/My_Papers/Counterfactual experience augmentation/ICONIP/figures/sumo-sta-exp.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
